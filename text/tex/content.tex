%=========================================================================

%- potreba mit 10-20 vysazenych stran / 20-40 normostran
%- na jednu plne potistenou stranu se vleze 1,65 (s nadpisem chapter) nebo 2,36 (bez nadpisu) normostran

% Setting the depth of sections numbering
\setcounter{secnumdepth}{2}
% Setting the depth of sections to appear in the table of contents.
\addtocontents{toc}{\protect\setcounter{tocdepth}{1}}

%=========================================================================
%=========================================================================
\chapter{Introduction}
% 1 - 2 ns

- napad: rozdelit uvod do pokapitol (podle https://uu.diva-portal.org/smash/get/diva2:648760/FULLTEXT01.pdf):
	- background
	- related work
	- problem formulation
	- system overview
	- thesis organization

- Slouží k zasazení řešené problematiky do širšího kontextu
- o optickych dalkomerech
- vyhody systemu (pasivni radar)
- vyuziti

- v podobě stručného obsahu jednotlivých kapitol definuje strukturu písemné práce.


-- dalsi kapitoly --

 formulaci cíle práce, charakteristiku současného stavu
 řešené problematiky a teoretická a odborná východiska řešených problémů.

 

%=========================================================================
%=========================================================================
\chapter{Related work}
% 1 - 2 ns

- srovnani s ji existujicimi aktivnimi (pasivnimi) radary

%=========================================================================
%=========================================================================
\chapter{System overview}
% 2 - 4 ns

- koncept systemu (rozlozeni jednotek, pouzity hardware, propojeni, ...)
- zmineni zakladniho knceptu behu celeho systemu od detekce cile az po jeho lokalizaci
- zminit zakladnich problematiky celeho systemu: zastaniceni, rektifikace, detekce, tracking, vyber jednotek pro sledovani, najezd po opticke ose, predani cile, triangulace, ...
- moznost rizeni jednotky pomoci joystiku/klavesnice
- zminit problematiku zastaniceni a rektifikace a odkaz na prislusnou kapitolu

%=========================================================================
%=========================================================================
\chapter{Camera unit} \label{txt:camera_unit}
% 2 - 4 ns

- z ceho sestava camera unit (zminit manipulator i kameru)
- návrh kinematického řetězce modelu manipulátoru
- ukazat 2D diagramy, 3D model z rvizu/gazeba
- fotka
- schema, kde bude ukazano, co je azimuthal a elevation axis

- PTU Flir
	- HW/SW limity pohybu
	- krokove motory
	- proble proklouznuti kroku

- nejake info o kamere


%=========================================================================
%=========================================================================
\chapter{Sensitivity analysis} \label{txt:sensitivity_analysis}
The precision of the system can be defined in the means of the frame-by-frame Euclidean distance between the estimated location and the real (ground truth) location of the given target. The precision is impacted by multiple independent factors, thus it is essential to perform the sensitivity analysis in order to discover and prospectively alleviate the most prominent contributors of the overall error. 

- vysvetleni typu chyb:
	- system error (systemova chyba)
		- nesoulad modelu CU s realnou konstrukci
		- nespravne mereni heading
		- detekce a tracking ?
	- uncertainty of the input of the system
		- GPS mereni
		- data inklinometru
	
- vysvetlit, ze se budeme snazit potlacit jen nektere chyby (neresime treba nepresnost mezi modelem a realnou CU z hledsiak translaci mezi klouby)

- rozdeleni na chybu rotace a translace
	- nepresnost v rotaci je daleko zavaznejsi, nez nepresnost v translaci
	- priklad a obrazek vlivu nepresnosti o x mrad na lokalizaci cile ve vzdalenosti y m/km

- zdroj chyb:
	- detekce
	- tracking
	- GPS pozice
	- natoceni vuci severu
	- rozliseni PTU
	- model PTU - translace mezi klouby
	- model PTU - rotace mezi klouby
	- uchyceni kamery
		- rotace podle opticke osy
		- rotace podle osy azimutu
		- rotace podle osy elevace
		
%- vysvetleni input a output systemu a pojmu sensitivity analysis (http://samples.sainsburysebooks.co.uk/9780470725177_sample_389211.pdf)

%=========================================================================
%=========================================================================
\chapter{Stationing and rectification}
% 2,5 - 3,5 ns

As explained in section \ref{txt:sensitivity_analysis} the precision of the whole system is dependent on on the uncertainty of the system input as well as on the imprecision of the camera unit construction. The process of stationing aims to alleviate the uncertainty of the system input while the main purpose of the rectification is to reduce the difference between the real camera unit and its model.

%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
\section{Stationing}

Since the stationing is considered to be already working subsystem of the whole project (and thus is not dealt with within the scope of this work) only the main principle will be briefly described. The stationing is composed of two parts: finding the geographical north and finding the relative azimuthal and elevation angles between each pair of camera units.

%.........................................................................
%.........................................................................
\subsection{Geographical north} \label{txt:geographical_north}

Though it is common practice to estimate the heading\footnote{Heading is the term used to describe the angle between the torso of the human body and the geographical north \cite{Henriksson648760}} using the magnetometer, this device is unsuitable for this project since the accuracy of the concurrent professional class magnetometers is insufficient (see Section \ref{txt:sensitivity_analysis}). For instance the accuracy of the magnetometers meant for compassing applications produced by Honeywell, the multinational company focusing on aerospace systems, range from hundreds to thousands of milliradians \cite{Honeywell:compassing_catalog}.

In order to find the orientation of each camera unit placed in the outdoor environment, distinctive landmarks (created either by human or nature) with known geographical positions are used. For each such a landmark the manipulator is rotated so that the optical axis of the camera would intersect that landmark and both the azimuth and elevation value is registered. Using triangulation the geographical position of the camera unit is derived. 

Different possible approach takes advantage of the celestial objects, such as the moon, sun or stars for which the current geographical position is known as well. Nevertheless this approach can only be used between the sunset and the dawn.

%.........................................................................
%.........................................................................
\subsection{Relative azimuth and elevation}

To further reduce the impact of the uncertainty of the system input produced by the GPS (see Section \ref{txt:sensitivity_analysis}) and the system error given by the imprecision of the heading estimation (see Section \ref{txt:geographical_north}) it is convenient to find the relative position of each camera unit with regards to the rest of the camera units.

The information about the geographical position of all camera units as obtained from the GPS sensors is distributed across the whole system. Each pair of camera units then automatically performs the following:

\begin{enumerate}
	\item Set the azimuth and elevation of the manipulator so that the optical axis of the camera would intersect the expected location of the LED target of the other camera unit.
	\item Using the visual clue adjust the azimuth and elevation so that the optical axis of the camera would intersect the center of the LED target of the other unit (see Figure \ref{fig:stationing_aiming}).
	\item Save the current azimuth and elevation values of both camera units and use those values to update the model of the system.
\end{enumerate}

%% Stationing process of one pair of the camera units
\begin{figure}[htb]
	\centering
	\includegraphics[width=14cm]{fig/stationing_aiming.png}
	\caption{The schema of stationing process where two camera units attempt to align the optical axes of their cameras so that they would intersect the LED target of the other unit.}
	\label{fig:stationing_aiming}
\end{figure}


%.........................................................................
%.........................................................................
\subsection{Horizontality}
Since the camera unit is expected to be placed in an unknown outdoor terrain, it will never stand on an ideally horizontal surface. Thus it is necessary to either ensure that the unevenness of the surface is compensated by the suitable setting of the camera unit's stand or both the side tilt and front tilt angles of the stand must be estimated and integrated to the model of the given camera unit. For these purposes the inclinometer attached to the base plane of the camera unit (see Section \ref{txt:camera_unit}) is used.


%-------------------------------------------------------------------------
%-------------------------------------------------------------------------
\section{Rectification}

The process of rectification serves the purpose of reducing the system error caused by the imprecise attachment of the camera to the manipulator. The model of the camera unit assumes that the camera is precisely attached to the manipulator so that the camera image sensor is positioned perpendicular to the azimuthal axis and the rows of the image sensor are parallel to the elevation axis (i.e. the camera is not rotated along the optical axis).

Regarding these requirements the rectification consists of three parts: rotation along the optical axis, rotation along the azimuthal axis, finding the default elevation angle.


%.........................................................................
%.........................................................................
\subsection{Rotation along the optical axis}

A custom made metal mount is attached to the bottom side of the camera. The mount is then attached to the manipulator using two opposing round tenons enabling for the rotation of the mount (together with camera) along the axis parallel to the optical axis of the camera (see Figure \ref{fig:rect_model_front_view}).

%% The front view of the model of the camera unit
\begin{figure}[htb]
	\centering
	\includegraphics[width=13cm]{fig/rect_model_front_view.png}
	\caption{Front view of the top part of the camera unit. The red arrow shows the possible rotation of the camera along the axis parallel to the optical axis.}
	\label{fig:rect_model_front_view}
\end{figure}

In this part the rectification target with three parallel horizontal black lines is used. Each line has different width so that the operator can select the most suitable one (given the distance of the target, ambient lighting conditions, etc.) As the first step a surveying automatic level is used to rotate the target so that the black lines become horizontal. Then the camera is pointed approximately to the center of the target. The camera image stream is blended with the same stream mirrored across the vertical axis. The operator then manually rotates the camera so that the black lines in this blended image stream appear visually aligned (see Figure \ref{fig:rect_mirrored_stream}). Once set, the mount with the camera is fixed to the manipulator using two set screws.

%% Rectification of the rows of the camera image sensor - original stream blended with the mirrored stream
\begin{figure}[htb]
	\centering
	\includegraphics[width=13cm]{fig/rect_mirrored_stream.png}
	\caption{A blended image stream from the camera before (left) and after (right) rotating the camera along the optical axis to the correct position.}
	\label{fig:rect_mirrored_stream}
\end{figure}

%.........................................................................
%.........................................................................
\subsection{Rotation along the azimuthal axis}

The mount can still rotate along the axis parallel to the azimuthal axis (see Figure \ref{fig:rect_model_top_view}). It is necessary to ensure that the optical axis of the camera is perpendicular to the elevation axis. 

%% The top view of the model of the camera unit
\begin{figure}[htb]
	\centering
	\includegraphics[width=13cm]{fig/rect_model_top_view.png}
	\caption{Top view of the top part of the camera unit. The red arrow shows the possible rotation of the camera along the axis parallel to the azimuthal axis.}
	\label{fig:rect_model_top_view}
\end{figure}

The same target from the first part of the rectification is used, but two black crosses are added to the selected horizontal black line. The distance $d_{ao}\ m$ between two crosses equals to the distance between the azimuthal and optical axis (which is known from the engineering design, see Figure \ref{fig:rect_azi_axis}). 

%% Photograph of the camera unit with the telescope mounted on the top
%% Screenshot of the digital crosshair and the offset
\begin{figure}[htb]
	\centering
	\begin{minipage}{.42\textwidth}
		\centering
		\includegraphics[width=.99\linewidth]{fig/rect_telescope.png}
		\captionof{figure}{A telescope mounted on top of the manipulator. A person looking through a telescope sees a crosshair - a tip of a triangle.}
		\label{fig:rect_telescope}
	\end{minipage}
	\hfill
	\begin{minipage}{.54\textwidth}
		\centering
		\includegraphics[width=.99\linewidth]{fig/rect_azi_axis.png}
		\captionof{figure}{Rectification target with the pairs of black crosses. The two crosses in a pair are $d_{ao}\ m$ appart. A digital corsshair is displayed in order to find the horizontal offset $d_{h}$.}
		\label{fig:rect_azi_axis}
	\end{minipage}
\end{figure}

A military optical monocular telescope (see Figure \ref{fig:rect_telescope}) is mounted on top of the manipulator. The optical axis of the telescope intersects the azimuthal axis, it is perpendicular to it and it intersects the left cross of a given pair on the rectification target. The camera is rotated so that its optical axis (represented by the digital crosshair) intersects the right cross on the target and then is fixed using set screws. As the screws are tightened the camera is unintentionally rotated a bit again which causes the visual offset between the crosshair and the cross on the target. The offset expressed in pixels is recorded and transformed to the default angle $\beta$ expressed in milliradians (see Figure) of rotation along Z-axis of the joint \texttt{camera} in the camera unit model (see Section \ref{txt:camera_unit}):

\begin{equation*}
\begin{aligned}
\beta &= \arccos\frac{focal\_length}{offset}, \\
offset &= pixel\_offset * pixel\_size
\end{aligned}
\end{equation*}

%% Geometry schema showing how to calculate angle beta - pixel offset
\begin{figure}[htb]
	\centering
	\includegraphics[width=13cm]{fig/rect_pixel_offset.pdf}
	\caption{The top view schema of a rectification target being projected to the image sensor of the camera. The value of the angle $\beta$ is one of the output of the rectification process.}
	\label{fig:rect_pixel_offset}
\end{figure}

%.........................................................................
%.........................................................................
\subsection{Finding the default elevation angle}

Given the application of the system the camera is expected to mainly observe the sky. Considering the limited elevation range of the manipulator \texttt{Flir PTU D46-70} (see Section \ref{txt:camera_unit}), the camera must be mounted to the manipulator with the default elevation angle approximately $-60^{\circ}$. However, after fixing the camera it is necessary to find default elevation angle precisely. 

For this purpose a pair of rectification targets, which consist of vertical black and white lines representing the marks of a ruler. The targets are positioned in a row with the distance of a few meters so that the front target would overlap approximately half of the rare target when observed from the camera. Both targets must be rotated so that the lines become horizontal, then the operator manually adjusts the elevation of the manipulator so that the digital crosshair would intersect the same mark on both targets where the two marks form a straight line (see figure \ref{fig:rect_default_elevation_angle}). Once found the current elevation angle is recorded and integrated to the model of the camera unit as an angle of rotation along the Y-axis of the joint \texttt{camera} (see Section \ref{txt:camera_unit}).

%% The rectification target for finding the default elevation angle.
\begin{figure}[htb]
	\centering
	\includegraphics[width=13cm]{fig/rect_default_elevation_angle.png}
	\caption{Front target of a pair of the rectification targets used to find a default elevation angle (left). A screenshot from the image stream of the camera with the crosshair focused on a row where the marks of the rulers align (right).}
	\label{fig:rect_default_elevation_angle}
\end{figure}


%=========================================================================
%=========================================================================
\chapter{Detection and tracking}
% 4,5 - 9 ns

- === DETEKCE VZDALENYCH OBJEKTU V OBRAZE ===
- === SLEDOVANI OBJEKTU VE VICEKAMEROVYCH SYSTEMECH ===
- === ALGORITMY VHODNE PRO RESENI ULOHY ===

- TLD
- moznost sdileni info o appearance modelu mezi CUs


%=========================================================================
%=========================================================================
\chapter{Cooperation among camera units}
% 1 - 4 ns

- vyber druhe jednotky pro trackovani cile
- najezd po opticke ose
- predani cile


%=========================================================================
%=========================================================================
\chapter{Target localization}
% 2,5 - 6 ns

- triangulace
- === LOKALIZACE OBJEKTU VE VICEKAMEROVYCH SYSTEMECH ===
- === ALGORITMY VHODNE PRO RESENI ULOHY ===

%=========================================================================
%=========================================================================
\chapter{Implementation}
% 2 - 4 ns

- C++
- pouziti ROSu, ukazat diagram z rqt\_graph, navrh komunikace pres zpravy
- gazebo - hardware in a loop
- predbezny navrh GUI


%=========================================================================
%=========================================================================
\chapter{Experiments and results}
% 1 - 3 ns

- vlastni datova sada
- experimenty na ziskena a porizene datove sade
- === EXPERIMENTY NA REALNYCH DATECH ===

%=========================================================================
%=========================================================================
\chapter{Conclusion}
% 1 - 2 ns

- zhodnocení dosažených výsledků se zvlášť vyznačeným vlastním přínosem studenta
- zhodnocení z pohledu dalšího vývoje projektu vzhledem k diplomové práci
- moznosti dalsiho vyvoje: modelovani okoli ve 3D nebo vyuziti teto info z mapy
- veci, co se zatim nebraly v uvahu
	- system je umisten na rozhrani dvou a vice UTM zon


